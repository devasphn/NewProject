"""
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    PRODUCTION CODEC TRAINING SCRIPT
    Version: 2.0 - Final Production Build
    
    Features:
    âœ… GAN Training (DAC Discriminator)
    âœ… Multi-GPU Support (DDP)
    âœ… Mixed Precision (FP16)
    âœ… Gradient Accumulation
    âœ… Learning Rate Scheduling
    âœ… Checkpoint Management
    âœ… TensorBoard Logging
    âœ… Audio Sample Logging
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""

import os
import sys
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader
from torch.cuda.amp import autocast, GradScaler
from torch.amp import autocast as new_autocast  # For newer PyTorch
from torch.optim.lr_scheduler import CosineAnnealingLR
import torchaudio
from pathlib import Path
import argparse
import json
import time
from datetime import datetime
from tqdm import tqdm
import numpy as np

# Local imports
from codec_production import ProductionCodec, CodecConfig
from discriminator_dac import DACDiscriminator, discriminator_loss, generator_adversarial_loss, feature_matching_loss


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# CONFIGURATION
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class TrainConfig:
    """Training configuration"""
    # Data
    data_dirs: list = None  # List of directories containing audio
    sample_rate: int = 16000
    segment_length: int = 32000  # 2 seconds at 16kHz
    
    # Training
    batch_size: int = 16
    num_epochs: int = 200
    gradient_accumulation: int = 2
    
    # Optimization
    gen_lr: float = 1e-4
    disc_lr: float = 1e-4
    betas: tuple = (0.5, 0.9)
    weight_decay: float = 0.01
    
    # Loss weights
    adv_weight: float = 1.0
    feat_weight: float = 10.0
    
    # GAN training
    disc_start_epoch: int = 5  # Start discriminator after N epochs
    
    # Checkpointing
    checkpoint_dir: str = "checkpoints_production"
    save_every: int = 5
    
    # Logging
    log_every: int = 100
    sample_every: int = 500
    
    # Hardware
    num_workers: int = 8  # Increased for faster data loading
    use_fp16: bool = True
    
    def __init__(self, **kwargs):
        for k, v in kwargs.items():
            setattr(self, k, v)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# DATASET
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class MultilingualAudioDataset(Dataset):
    """
    Dataset for multilingual audio training
    Supports: Telugu, Hindi, English, Tamil, and more
    """
    def __init__(self, data_dirs: list, sample_rate: int = 16000, 
                 segment_length: int = 32000, normalize_db: float = -16.0):
        self.sample_rate = sample_rate
        self.segment_length = segment_length
        self.normalize_db = normalize_db
        
        # Collect all audio files from all directories
        self.audio_files = []
        audio_extensions = {'.wav', '.mp3', '.flac', '.ogg', '.m4a'}
        
        for data_dir in data_dirs:
            data_path = Path(data_dir)
            if not data_path.exists():
                print(f"âš ï¸ Directory not found: {data_dir}")
                continue
            
            for ext in audio_extensions:
                self.audio_files.extend(list(data_path.rglob(f"*{ext}")))
        
        print(f"ðŸ“ Found {len(self.audio_files)} audio files across {len(data_dirs)} directories")
        
        if len(self.audio_files) == 0:
            raise ValueError("No audio files found! Check your data directories.")
    
    def __len__(self):
        return len(self.audio_files)
    
    def __getitem__(self, idx):
        audio_path = self.audio_files[idx]
        
        try:
            # Load audio
            waveform, sr = torchaudio.load(str(audio_path))
            
            # Convert to mono
            if waveform.shape[0] > 1:
                waveform = waveform.mean(dim=0, keepdim=True)
            
            # Resample if needed
            if sr != self.sample_rate:
                resampler = torchaudio.transforms.Resample(sr, self.sample_rate)
                waveform = resampler(waveform)
            
            # Get segment
            if waveform.shape[1] >= self.segment_length:
                # Random crop
                start = torch.randint(0, waveform.shape[1] - self.segment_length + 1, (1,)).item()
                waveform = waveform[:, start:start + self.segment_length]
            else:
                # Pad short audio
                padding = self.segment_length - waveform.shape[1]
                waveform = F.pad(waveform, (0, padding))
            
            # RMS Normalization
            waveform = self._normalize_rms(waveform)
            
            # Clamp to [-1, 1]
            waveform = torch.clamp(waveform, -1.0, 1.0)
            
            return waveform
            
        except Exception as e:
            # Return random noise if file fails to load
            print(f"âš ï¸ Failed to load {audio_path}: {e}")
            return torch.randn(1, self.segment_length) * 0.1
    
    def _normalize_rms(self, audio: torch.Tensor) -> torch.Tensor:
        """Normalize audio to target RMS (dB)"""
        rms = torch.sqrt(torch.mean(audio ** 2))
        if rms > 1e-8:
            target_rms = 10 ** (self.normalize_db / 20)
            audio = audio * (target_rms / rms)
        return audio


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# TRAINER
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class ProductionCodecTrainer:
    """Production codec trainer with GAN training"""
    
    def __init__(self, config: TrainConfig, codec_config: CodecConfig = None):
        self.config = config
        self.codec_config = codec_config or CodecConfig()
        
        # Setup device
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        print(f"ðŸ–¥ï¸ Using device: {self.device}")
        
        # Create models
        print("\nðŸ“¦ Initializing models...")
        self.codec = ProductionCodec(self.codec_config).to(self.device)
        self.discriminator = DACDiscriminator().to(self.device)
        
        # Optimizers
        self.gen_optimizer = torch.optim.AdamW(
            self.codec.parameters(),
            lr=config.gen_lr,
            betas=config.betas,
            weight_decay=config.weight_decay
        )
        self.disc_optimizer = torch.optim.AdamW(
            self.discriminator.parameters(),
            lr=config.disc_lr,
            betas=config.betas,
            weight_decay=config.weight_decay
        )
        
        # Schedulers
        self.gen_scheduler = CosineAnnealingLR(self.gen_optimizer, T_max=config.num_epochs)
        self.disc_scheduler = CosineAnnealingLR(self.disc_optimizer, T_max=config.num_epochs)
        
        # Mixed precision
        self.scaler = GradScaler() if config.use_fp16 else None
        
        # Create dataset
        print("\nðŸ“ Loading dataset...")
        self.dataset = MultilingualAudioDataset(
            data_dirs=config.data_dirs,
            sample_rate=config.sample_rate,
            segment_length=config.segment_length
        )
        
        self.dataloader = DataLoader(
            self.dataset,
            batch_size=config.batch_size,
            shuffle=True,
            num_workers=config.num_workers,
            pin_memory=True,
            drop_last=True
        )
        
        # Setup checkpointing
        self.checkpoint_dir = Path(config.checkpoint_dir)
        self.checkpoint_dir.mkdir(parents=True, exist_ok=True)
        
        # Training state
        self.epoch = 0
        self.global_step = 0
        self.best_loss = float('inf')
        
        # Logging
        self.setup_logging()
    
    def setup_logging(self):
        """Setup TensorBoard logging"""
        try:
            from torch.utils.tensorboard import SummaryWriter
            log_dir = self.checkpoint_dir / "logs" / datetime.now().strftime("%Y%m%d_%H%M%S")
            self.writer = SummaryWriter(log_dir)
            print(f"ðŸ“Š TensorBoard logging to: {log_dir}")
        except ImportError:
            self.writer = None
            print("âš ï¸ TensorBoard not available")
    
    def save_checkpoint(self, name: str = None, is_best: bool = False):
        """Save training checkpoint"""
        if name is None:
            name = f"codec_epoch_{self.epoch}"
        
        checkpoint = {
            'epoch': self.epoch,
            'global_step': self.global_step,
            'codec_state_dict': self.codec.state_dict(),
            'discriminator_state_dict': self.discriminator.state_dict(),
            'gen_optimizer_state_dict': self.gen_optimizer.state_dict(),
            'disc_optimizer_state_dict': self.disc_optimizer.state_dict(),
            'gen_scheduler_state_dict': self.gen_scheduler.state_dict(),
            'disc_scheduler_state_dict': self.disc_scheduler.state_dict(),
            'best_loss': self.best_loss,
            'codec_config': self.codec_config.__dict__,
        }
        
        path = self.checkpoint_dir / f"{name}.pt"
        torch.save(checkpoint, path)
        print(f"ðŸ’¾ Saved checkpoint: {path}")
        
        if is_best:
            best_path = self.checkpoint_dir / "best_codec.pt"
            torch.save(checkpoint, best_path)
            print(f"â­ New best model saved!")
    
    def load_checkpoint(self, path: str):
        """Load training checkpoint"""
        print(f"ðŸ“‚ Loading checkpoint: {path}")
        checkpoint = torch.load(path, map_location=self.device)
        
        self.codec.load_state_dict(checkpoint['codec_state_dict'])
        self.discriminator.load_state_dict(checkpoint['discriminator_state_dict'])
        self.gen_optimizer.load_state_dict(checkpoint['gen_optimizer_state_dict'])
        self.disc_optimizer.load_state_dict(checkpoint['disc_optimizer_state_dict'])
        self.gen_scheduler.load_state_dict(checkpoint['gen_scheduler_state_dict'])
        self.disc_scheduler.load_state_dict(checkpoint['disc_scheduler_state_dict'])
        
        self.epoch = checkpoint['epoch']
        self.global_step = checkpoint['global_step']
        self.best_loss = checkpoint.get('best_loss', float('inf'))
        
        print(f"âœ… Resumed from epoch {self.epoch}, step {self.global_step}")
    
    def train_step(self, audio: torch.Tensor, use_disc: bool = True):
        """Single training step"""
        audio = audio.to(self.device)
        
        losses = {}
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # DISCRIMINATOR UPDATE
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if use_disc:
            self.disc_optimizer.zero_grad()
            
            with autocast(enabled=self.config.use_fp16):
                # Generate fake audio
                with torch.no_grad():
                    output = self.codec(audio)
                    fake_audio = output['audio']
                
                # Discriminator forward
                real_logits, real_features = self.discriminator(audio)
                fake_logits, fake_features = self.discriminator(fake_audio.detach())
                
                # Discriminator loss
                disc_loss, real_loss, fake_loss = discriminator_loss(real_logits, fake_logits)
            
            if self.scaler:
                self.scaler.scale(disc_loss).backward()
                self.scaler.unscale_(self.disc_optimizer)
                torch.nn.utils.clip_grad_norm_(self.discriminator.parameters(), 1.0)
                self.scaler.step(self.disc_optimizer)
            else:
                disc_loss.backward()
                torch.nn.utils.clip_grad_norm_(self.discriminator.parameters(), 1.0)
                self.disc_optimizer.step()
            
            losses['disc_loss'] = disc_loss.item()
            losses['disc_real'] = real_loss.item()
            losses['disc_fake'] = fake_loss.item()
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # GENERATOR UPDATE
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        self.gen_optimizer.zero_grad()
        
        with autocast(enabled=self.config.use_fp16):
            # Forward pass
            output = self.codec(audio)
            fake_audio = output['audio']
            
            # Reconstruction losses from codec
            gen_loss = output['loss']
            
            if use_disc:
                # Adversarial loss
                fake_logits, fake_features = self.discriminator(fake_audio)
                real_logits, real_features = self.discriminator(audio)
                
                adv_loss = generator_adversarial_loss(fake_logits)
                feat_loss = feature_matching_loss(real_features, fake_features)
                
                gen_loss = gen_loss + self.config.adv_weight * adv_loss + self.config.feat_weight * feat_loss
                
                losses['adv_loss'] = adv_loss.item()
                losses['feat_loss'] = feat_loss.item()
        
        if self.scaler:
            self.scaler.scale(gen_loss).backward()
            self.scaler.unscale_(self.gen_optimizer)
            torch.nn.utils.clip_grad_norm_(self.codec.parameters(), 1.0)
            self.scaler.step(self.gen_optimizer)
            self.scaler.update()  # Update scaler once per training step
        else:
            gen_loss.backward()
            torch.nn.utils.clip_grad_norm_(self.codec.parameters(), 1.0)
            self.gen_optimizer.step()
        
        # Record losses
        losses['gen_loss'] = gen_loss.item()
        losses['recon_loss'] = output['recon_loss'].item()
        losses['vq_loss'] = output['vq_loss'].item()
        losses['spectral_loss'] = output['spectral_loss'].item()
        losses['mel_loss'] = output['mel_loss'].item()
        losses['semantic_loss'] = output['semantic_loss'].item()
        
        return losses
    
    def train_epoch(self):
        """Train one epoch"""
        self.codec.train()
        self.discriminator.train()
        
        use_disc = self.epoch >= self.config.disc_start_epoch
        
        epoch_losses = {}
        pbar = tqdm(self.dataloader, desc=f"Epoch {self.epoch}")
        
        for batch_idx, audio in enumerate(pbar):
            losses = self.train_step(audio, use_disc=use_disc)
            
            # Accumulate losses
            for k, v in losses.items():
                if k not in epoch_losses:
                    epoch_losses[k] = []
                epoch_losses[k].append(v)
            
            # Update progress bar
            pbar.set_postfix({
                'gen': f"{losses['gen_loss']:.3f}",
                'recon': f"{losses['recon_loss']:.3f}",
                'vq': f"{losses['vq_loss']:.3f}",
            })
            
            # Logging
            if self.global_step % self.config.log_every == 0 and self.writer:
                for k, v in losses.items():
                    self.writer.add_scalar(f"train/{k}", v, self.global_step)
            
            self.global_step += 1
        
        # Epoch averages
        avg_losses = {k: np.mean(v) for k, v in epoch_losses.items()}
        return avg_losses
    
    def validate(self):
        """Validation pass"""
        self.codec.eval()
        
        total_loss = 0
        num_batches = min(50, len(self.dataloader))  # Validate on subset
        
        with torch.no_grad():
            for i, audio in enumerate(self.dataloader):
                if i >= num_batches:
                    break
                
                audio = audio.to(self.device)
                output = self.codec(audio)
                total_loss += output['loss'].item()
        
        avg_loss = total_loss / num_batches
        return avg_loss
    
    def train(self):
        """Full training loop"""
        print("\n" + "="*60)
        print("STARTING PRODUCTION CODEC TRAINING")
        print("="*60)
        print(f"Epochs: {self.config.num_epochs}")
        print(f"Batch size: {self.config.batch_size}")
        print(f"Dataset size: {len(self.dataset)}")
        print(f"Steps per epoch: {len(self.dataloader)}")
        print(f"Discriminator starts at epoch: {self.config.disc_start_epoch}")
        print("="*60 + "\n")
        
        for epoch in range(self.epoch, self.config.num_epochs):
            self.epoch = epoch
            
            # Train
            start_time = time.time()
            train_losses = self.train_epoch()
            epoch_time = time.time() - start_time
            
            # Validate
            val_loss = self.validate()
            
            # Update schedulers
            self.gen_scheduler.step()
            self.disc_scheduler.step()
            
            # Print epoch summary
            print(f"\nðŸ“Š Epoch {epoch} Summary (took {epoch_time/60:.1f} min):")
            print(f"   Gen Loss: {train_losses['gen_loss']:.4f}")
            print(f"   Recon Loss: {train_losses['recon_loss']:.4f}")
            print(f"   VQ Loss: {train_losses['vq_loss']:.4f}")
            print(f"   Val Loss: {val_loss:.4f}")
            if 'disc_loss' in train_losses:
                print(f"   Disc Loss: {train_losses['disc_loss']:.4f}")
            
            # Save checkpoint
            if (epoch + 1) % self.config.save_every == 0:
                self.save_checkpoint()
            
            # Save best
            if val_loss < self.best_loss:
                self.best_loss = val_loss
                self.save_checkpoint("best_codec", is_best=True)
            
            # Log to tensorboard
            if self.writer:
                self.writer.add_scalar("epoch/val_loss", val_loss, epoch)
                self.writer.add_scalar("epoch/lr", self.gen_scheduler.get_last_lr()[0], epoch)
        
        print("\nâœ… Training complete!")
        self.save_checkpoint("final_codec")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# MAIN
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def main():
    parser = argparse.ArgumentParser(description="Train Production Codec")
    
    # Data
    parser.add_argument("--data_dirs", nargs="+", required=True,
                       help="Directories containing audio files")
    
    # Training
    parser.add_argument("--batch_size", type=int, default=16)
    parser.add_argument("--num_epochs", type=int, default=200)
    parser.add_argument("--gen_lr", type=float, default=1e-4)
    parser.add_argument("--disc_lr", type=float, default=1e-4)
    
    # Checkpointing
    parser.add_argument("--checkpoint_dir", type=str, default="checkpoints_production")
    parser.add_argument("--resume", type=str, default=None,
                       help="Path to checkpoint to resume from")
    
    # Hardware
    parser.add_argument("--num_workers", type=int, default=4)
    parser.add_argument("--no_fp16", action="store_true")
    
    args = parser.parse_args()
    
    # Create config
    train_config = TrainConfig(
        data_dirs=args.data_dirs,
        batch_size=args.batch_size,
        num_epochs=args.num_epochs,
        gen_lr=args.gen_lr,
        disc_lr=args.disc_lr,
        checkpoint_dir=args.checkpoint_dir,
        num_workers=args.num_workers,
        use_fp16=not args.no_fp16,
    )
    
    # Create trainer
    trainer = ProductionCodecTrainer(train_config)
    
    # Resume if specified
    if args.resume:
        trainer.load_checkpoint(args.resume)
    
    # Train
    trainer.train()


if __name__ == "__main__":
    main()
