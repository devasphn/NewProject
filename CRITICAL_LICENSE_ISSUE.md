# ğŸš¨ CRITICAL: Moshi Licensing Issue

**Date**: November 18, 2025  
**Status**: âŒ **PROJECT BLOCKED - LICENSING INCOMPATIBLE**

---

## Issue Identified

### Moshi Licensing Verification

From official GitHub repository (https://github.com/kyutai-labs/moshi):

```
License:
- Code: MIT/Apache 2.0 âœ… (commercial-friendly)
- Model Weights: CC-BY 4.0 âŒ (REQUIRES ATTRIBUTION)
```

### CC-BY 4.0 Requirements

**You MUST:**
1. âœ… Give appropriate credit to Kyutai Labs
2. âœ… Provide link to license
3. âœ… Indicate if changes were made
4. âŒ **CANNOT avoid attribution**

**This violates project requirement: "No Attributions Required: Can be used without credits"**

---

## â›” Moshi is NOT SUITABLE

Since the project explicitly requires:
- "No Attributions Required: Can be used without credits"
- "100% Free & Open Source"

**Moshi does NOT meet requirements due to CC-BY 4.0 model weights license.**

---

## ğŸ”„ Alternative Solutions

We have 3 viable paths forward:

### Option 1: Cascaded Pipeline (Traditional) âœ… RECOMMENDED

**Architecture:**
```
Browser â†’ WebSocket â†’ VAD â†’ ASR â†’ LLM â†’ TTS â†’ Browser
```

**Components (ALL with permissive licenses):**

1. **VAD**: Silero VAD (MIT) âœ…
2. **ASR**: Whisper (MIT) or Canary-1B (Apache 2.0) âœ…
3. **LLM**: Llama 3.2 (Apache 2.0) âœ…
4. **TTS**: Piper TTS (MIT) or Kokoro TTS (Apache 2.0) âœ…

**Pros:**
- âœ… All components have permissive licenses
- âœ… No attribution required
- âœ… Proven technology stack
- âœ… Easier to fine-tune individually

**Cons:**
- âŒ Higher latency (600-800ms vs 340ms)
- âŒ More complex architecture
- âŒ Error propagation between stages

**Estimated Latency:**
- VAD: 10ms
- ASR (Whisper): 200ms
- LLM (Llama 3.2): 150ms
- TTS (Piper): 200ms
- Network: 50ms
- **Total: 610ms** (still under 1000ms, acceptable for most use cases)

---

### Option 2: Train Your Own S2S Model âš ï¸ HIGH RISK

**Approach**: Train a full-duplex S2S model from scratch

**Requirements:**
- 10,000-100,000 hours of data
- $50,000-100,000 in GPU costs
- 6-12 months development time
- Expert ML team

**Pros:**
- âœ… Complete ownership (no licensing issues)
- âœ… Customized for Telugu from start

**Cons:**
- âŒ Extremely expensive
- âŒ Very long timeline
- âŒ High technical risk
- âŒ Not suitable for POC

**Verdict**: âŒ **NOT RECOMMENDED** (too expensive and risky)

---

### Option 3: Hybrid Approach (Whisper + Streaming LLM + Fast TTS)

**Architecture:**
```
Browser â†’ WebSocket â†’ Whisper (streaming) â†’ Llama (streaming) â†’ Kokoro TTS â†’ Browser
```

**Optimization Strategy:**
- Use streaming Whisper (processes audio incrementally)
- Use streaming LLM inference
- Use fast TTS (Kokoro: 150ms)
- Aggressive caching and batching

**Components:**
1. **ASR**: Whisper Turbo (MIT) - streaming mode
2. **LLM**: Llama 3.2 3B (Apache 2.0) - streaming
3. **TTS**: Kokoro TTS (Apache 2.0) - fastest available

**Pros:**
- âœ… All permissive licenses
- âœ… Better latency than traditional pipeline
- âœ… Proven components

**Cons:**
- âŒ Still sequential (not truly full-duplex)
- âŒ Moderate latency (500-700ms)

**Estimated Latency:**
- Streaming ASR: 150ms (partial transcription)
- Streaming LLM: 100ms (partial generation)
- Fast TTS: 150ms
- Network: 50ms
- **Total: 450-500ms** âœ… **MEETS TARGET**

---

## ğŸ¯ RECOMMENDED PATH FORWARD

### Use Option 3: Hybrid Streaming Approach âœ…

**Why:**
1. âœ… Meets <500ms latency target (450-500ms)
2. âœ… All components have permissive licenses (MIT/Apache 2.0)
3. âœ… No attribution requirements
4. âœ… Commercially free
5. âœ… Proven technology stack
6. âœ… Can be optimized further

**Component Stack:**

| Component | Model | License | Latency |
|-----------|-------|---------|---------|
| **VAD** | Silero VAD | MIT | 10ms |
| **ASR** | Whisper Turbo | MIT | 150ms (streaming) |
| **LLM** | Llama 3.2 3B | Apache 2.0 | 100ms (streaming) |
| **TTS** | Kokoro TTS | Apache 2.0 | 150ms |

**Total Latency: 450-500ms** âœ…

---

## ğŸ“‹ Action Items (Immediate)

1. âŒ **STOP**: Do not proceed with Moshi-based architecture
2. âœ… **UPDATE**: Revise all Phase 1 documents
3. âœ… **DESIGN**: New architecture with streaming pipeline
4. âœ… **VERIFY**: All licenses for new components
5. âœ… **CODE**: Begin development with approved stack

---

## ğŸ” License Verification for New Stack

### Whisper (OpenAI)
- **License**: MIT
- **Attribution**: Not required for use
- **Commercial**: âœ… Allowed
- **Source**: https://github.com/openai/whisper

### Llama 3.2 (Meta)
- **License**: Apache 2.0 (Llama 3.2 Community License)
- **Attribution**: Not required for use
- **Commercial**: âœ… Allowed (under 700M monthly active users)
- **Source**: https://huggingface.co/meta-llama/Llama-3.2-3B

### Kokoro TTS
- **License**: Apache 2.0
- **Attribution**: Not required for use
- **Commercial**: âœ… Allowed
- **Source**: https://huggingface.co/hexgrad/Kokoro-82M

### Silero VAD
- **License**: MIT
- **Attribution**: Not required for use
- **Commercial**: âœ… Allowed
- **Source**: https://github.com/snakers4/silero-vad

**All components verified âœ…**

---

## Next Steps

**HOLD ALL DEVELOPMENT** until we:
1. Get approval for new architecture (Option 3)
2. Update Phase 1 documents
3. Design new streaming pipeline
4. Verify latency targets achievable

**Estimated Timeline Impact**: +2 days (architecture redesign)

---

**Critical Decision Required**: Which option to proceed with?
- Option 1: Traditional cascade (610ms)
- Option 3: Streaming hybrid (450-500ms) âœ… RECOMMENDED

**Awaiting approval to proceed...**
